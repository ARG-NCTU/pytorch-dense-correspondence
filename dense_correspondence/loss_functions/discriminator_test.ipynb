{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "\n",
    "import dense_correspondence\n",
    "from dense_correspondence.evaluation.evaluation import *\n",
    "import dense_correspondence.correspondence_tools.correspondence_plotter as correspondence_plotter\n",
    "from dense_correspondence.dataset.dense_correspondence_dataset_masked import ImageType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', \n",
    "                               'dense_correspondence', 'evaluation', 'evaluation.yaml')\n",
    "config = utils.getDictFromYamlFilename(config_filename)\n",
    "default_config = utils.get_defaults_config()\n",
    "\n",
    "\n",
    "utils.set_cuda_visible_devices([0])\n",
    "dce = DenseCorrespondenceEvaluation(config)\n",
    "DCE = DenseCorrespondenceEvaluation\n",
    "\n",
    "\n",
    "network_name = \"3_hat_train_6\"\n",
    "dcn = dce.load_network_from_config(network_name)\n",
    "dataset = dcn.load_training_dataset()\n",
    "\n",
    "train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'training', 'training.yaml')\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "dataset._setup_data_load_types()\n",
    "dataset.set_parameters_from_training_config(train_config)\n",
    "\n",
    "dcn.eval()\n",
    "\n",
    "scene_name_a = dataset.get_random_scene_name()\n",
    "img_a_idx = dataset.get_random_image_index(scene_name_a)\n",
    "rgb_a, _, _, _ = dataset.get_rgbd_mask_pose(scene_name_a, img_a_idx)\n",
    "\n",
    "scene_name_b = dataset.get_random_scene_name()\n",
    "img_b_idx = dataset.get_random_image_index(scene_name_b)\n",
    "rgb_b, _, _, _ = dataset.get_rgbd_mask_pose(scene_name_b, img_b_idx)\n",
    "\n",
    "rgb_a_tensor = dataset.rgb_image_to_tensor(rgb_a)\n",
    "rgb_b_tensor = dataset.rgb_image_to_tensor(rgb_b)\n",
    "\n",
    "# these are Variables holding torch.FloatTensors, first grab the data, then convert to numpy\n",
    "res_a = dcn.forward_single_image_tensor(rgb_a_tensor)\n",
    "res_b = dcn.forward_single_image_tensor(rgb_b_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print res_a.data.shape\n",
    "\n",
    "# put in N, C, H, W\n",
    "res_a_shaped = res_a.permute(2,0,1).unsqueeze(0)\n",
    "print res_a_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# pool of square window of size=3, stride=2\n",
    "# AvgPool2d wants: N, C, H, W\n",
    "m = nn.AvgPool2d(8, stride=8)\n",
    "# pool of non-square window\n",
    "input = Variable(torch.randn(20, 16, 48, 32))\n",
    "output = m(input)\n",
    "print  output.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(res_a_shaped)\n",
    "print output.shape\n",
    "output_unshaped = output.squeeze(0).permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(res_a.data.cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(output_unshaped.data.cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_segmentation_detection.models.resnet_dilated as resnet_dilated\n",
    "\n",
    "class dcn_discriminator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(dcn_discriminator, self).__init__()\n",
    "        self.avg_pool = nn.AvgPool2d(8, stride=8)\n",
    "        self.r18 = resnet_dilated.Resnet18_8s(num_classes=num_classes)\n",
    "        # 8, 10 is hardcoded for 640 x 480 at moment,\n",
    "        # would be easy to calc general param\n",
    "        self.fc = nn.Linear(num_classes*8*10, num_classes)\n",
    "        \n",
    "    def forward(self, x, HWC_shape=False):\n",
    "        \"\"\"\n",
    "        This forward() directly takes \"res_a\" out of our DCN (dense descriptor network)\n",
    "        and sends it to a 1 x 3 Tensor of one-hot encodings for class prediction\n",
    "        \"\"\"\n",
    "        if HWC_shape:\n",
    "            x = x.permute(2,0,1).unsqueeze(0)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.r18.resnet18_8s(x)\n",
    "        x = x.view(-1)\n",
    "        x = self.fc(x).unsqueeze(0)\n",
    "        return x\n",
    "    \n",
    "# currently 6 because using with 6 hats dataset\n",
    "# but should automate this easily\n",
    "dcn_d = dcn_discriminator(num_classes=6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dcn_d(res_a, HWC_shape=True)\n",
    "\n",
    "#predictions[0,1] = 0\n",
    "#predictions[0,2] = 0\n",
    "print predictions\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "label = Variable(torch.LongTensor([0]), requires_grad=False).cuda()\n",
    "d_loss = criterion(predictions, label)\n",
    "print d_loss\n",
    "\n",
    "label = Variable(torch.LongTensor([1]), requires_grad=False).cuda()\n",
    "d_loss = criterion(predictions, label)\n",
    "print d_loss\n",
    "\n",
    "label = Variable(torch.LongTensor([2]), requires_grad=False).cuda()\n",
    "d_loss = criterion(predictions, label)\n",
    "print d_loss\n",
    "\n",
    "softmax = nn.LogSoftmax()\n",
    "print softmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "d_optimizer = optim.Adam(dcn_d.parameters(), lr=1.0e-4, weight_decay=1.0e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=10, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(data_loader, 0):\n",
    "    print i\n",
    "    \n",
    "    match_type, \\\n",
    "    img_a, img_b, \\\n",
    "    matches_a, matches_b, \\\n",
    "    masked_non_matches_a, masked_non_matches_b, \\\n",
    "    background_non_matches_a, background_non_matches_b, \\\n",
    "    blind_non_matches_a, blind_non_matches_b, \\\n",
    "    metadata = data\n",
    "    \n",
    "    if (match_type == -1).all():\n",
    "        print \"\\n empty data, continuing \\n\"\n",
    "        continue\n",
    "    \n",
    "    label = metadata[\"object_id_int\"]\n",
    "    \n",
    "    img_a = Variable(img_a.cuda(), requires_grad=False)\n",
    "    img_b = Variable(img_b.cuda(), requires_grad=False)\n",
    "    \n",
    "    image_a_pred = dcn.forward(img_a)\n",
    "    image_b_pred = dcn.forward(img_b) \n",
    "    \n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    predictions_a = dcn_d(image_a_pred)\n",
    "    predictions_b = dcn_d(image_b_pred)\n",
    "    \n",
    "    label = Variable(label, requires_grad=False).cuda()\n",
    "    d_loss = criterion(predictions_a, label) + criterion(predictions_b, label)\n",
    "    \n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    print d_loss.data[0], predictions_a, predictions_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
