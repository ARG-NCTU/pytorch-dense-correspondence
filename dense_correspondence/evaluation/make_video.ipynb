{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "\n",
    "import dense_correspondence\n",
    "from dense_correspondence.evaluation.evaluation import *\n",
    "import dense_correspondence.correspondence_tools.correspondence_plotter as correspondence_plotter\n",
    "from dense_correspondence.dataset.dense_correspondence_dataset_masked import ImageType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', \n",
    "                               'dense_correspondence', 'evaluation', 'evaluation.yaml')\n",
    "config = utils.getDictFromYamlFilename(config_filename)\n",
    "default_config = utils.get_defaults_config()\n",
    "\n",
    "\n",
    "utils.set_cuda_visible_devices([0])\n",
    "dce = DenseCorrespondenceEvaluation(config)\n",
    "DCE = DenseCorrespondenceEvaluation\n",
    "\n",
    "\n",
    "\n",
    "network_name = \"caterpillar_standard_3\"\n",
    "dcn = dce.load_network_from_config(network_name)\n",
    "dcn.eval()\n",
    "dataset = dcn.load_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from plotting import normalize_descriptor\n",
    "import time\n",
    "\n",
    "## Usage:\n",
    "## change the full_rgb_only_path\n",
    "## run the full notebook\n",
    "\n",
    "full_rgb_only_path = \"/media/peteflo/3TBbackup/dense_correspondence/pdc/logs_proto/2018-04-27-19-39-51/processed/rgb_only\"\n",
    "save_path = os.path.join(full_rgb_only_path, \"../descriptors_only_masked\")\n",
    "os.system(\"mkdir -p \"+ save_path)\n",
    "\n",
    "descriptor_image_stats = dcn.descriptor_image_stats\n",
    "\n",
    "for i in sorted(os.listdir(full_rgb_only_path)):\n",
    "    start = time.time()\n",
    "    if \"rgb.png\" not in i:\n",
    "        continue\n",
    "\n",
    "    rgb_filename = os.path.join(full_rgb_only_path, i)\n",
    "    rgb_a = Image.open(rgb_filename).convert('RGB')\n",
    "\n",
    "    # compute dense descriptors\n",
    "    # This takes in a PIL image!\n",
    "    rgb_a_tensor = dataset.rgb_image_to_tensor(rgb_a)\n",
    "\n",
    "    # these are Variables holding torch.FloatTensors, first grab the data, then convert to numpy\n",
    "    res_a = dcn.forward_single_image_tensor(rgb_a_tensor).data.cpu().numpy()\n",
    "\n",
    "    res_a = normalize_descriptor(res_a, descriptor_image_stats[\"mask_image\"])\n",
    "    save_file_name = os.path.join(save_path, i)\n",
    "    plt.imsave(save_file_name, res_a)\n",
    "    print \"forward and saving at rate\", time.time()-start\n",
    "\n",
    "\n",
    "plt.imshow(res_a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best so far\n",
    "# ffmpeg -framerate 30 -pattern_type glob -i '*.png' -c:v libx264 -r 30 out.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"cd \"+save_path+\" && ffmpeg -framerate 30 -pattern_type glob -i '*.png' -c:v libx264 -r 30 out.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This currently doesn't work\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'DIVX')  # 'x264' doesn't work\n",
    "# out = cv2.VideoWriter('./videos/001_output.mp4',fourcc, 29.0, size, False)  # 'False' for 1-ch instead of 3-ch for color\n",
    "# fgbg= cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# while (capture.isOpened()):  #while Ture:\n",
    "#     ret, img = capture.read()\n",
    "#     if ret==True:\n",
    "#         fgmask = fgbg.apply(img)\n",
    "#         out.write(fgmask)\n",
    "#         cv2.imshow('img',fgmask)\n",
    "\n",
    "#     #if(cv2.waitKey(27)!=-1):  # observed it will close the imshow window immediately\n",
    "#     #    break                 # so change to below\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# capture.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
